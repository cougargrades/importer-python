#!/usr/bin/env python3

import os
import os.path
import sys
import json
import argparse
import time
import copy
import sqlite3
import statistics
from tqdm import tqdm
from halo import Halo

parser = argparse.ArgumentParser(description='Generate instructor JSON files from SQLite database')
parser.add_argument('--docs', dest='folder', default=None,
                    help='Folder where .jsonl files are stored')
parser.add_argument('dbfile', metavar='records.db', type=str,
                    help='Path to the SQLite database generated by csv2db.py')
args = parser.parse_args()

# check arguments
if not os.path.isfile(args.dbfile):
    print(f'{args.dbfile} is not a file.')
    exit(1)

if args.folder == None:
    print(f'--docs must be a folder name.')
    exit(1)
else:
    # if not a directory and not an existing file
    if not os.path.isdir(args.folder) and not os.path.isfile(args.folder):
        # create the folder
        os.mkdir(args.folder)
    if(not os.path.isdir(os.path.join(args.folder, 'catalog')) and not os.path.isfile(os.path.join(args.folder, 'catalog'))):
        # expected data is missing
        print(f'The `catalog` folder is missing from {args.folder}')
        exit(1)
    if(not os.path.isdir(os.path.join(args.folder, 'catalog_meta')) and not os.path.isfile(os.path.join(args.folder, 'catalog_meta'))):
        # expected data is missing
        print(f'The `catalog_meta` folder is missing from {args.folder}')
        exit(1)
    if(not os.path.isdir(os.path.join(args.folder, 'instructors')) and not os.path.isfile(os.path.join(args.folder, 'instructors'))):
        # create the subfolder
        os.mkdir(os.path.join(args.folder, 'instructors'))

def file_len(fname):
    with open(fname) as f:
        for i, l in enumerate(f):
            pass
    return i + 1

def update_instructor(name, data, merge=False):
    post = {}
    if os.path.isfile(os.path.join(args.folder, 'instructors', name)):
        with open(os.path.join(args.folder, 'instructors', name), 'r') as f:
            pre = json.loads(f.read())
            post = copy.deepcopy(pre)
            for key, value in data.items():
                # when merging...
                if merge:
                    # if a value is numeric and existed in the previous file
                    if str(value).isnumeric() and pre[key] != None:
                        # treat the provided value as a delta
                        post[key] += value

                post[key] = value
    else:
        post = copy.deepcopy(data)
    with open(os.path.join(args.folder, 'instructors', name), 'w') as f:
        f.write(f'''{json.dumps(post)}\n''')

def get_instructor(name):
    if os.path.isfile(os.path.join(args.folder, 'instructors', name)):
        with open(os.path.join(args.folder, 'instructors', name), 'r') as f:
            return json.loads(f.read())
    else:
        return None

# https://docs.python.org/3/library/sqlite3.html#sqlite3.Connection.row_factory
def dict_factory(cursor, row):
    d = {}
    for idx, col in enumerate(cursor.description):
        d[col[0]] = row[idx]
    return d

def statrange(x):
    return x[len(x)-1] - x[0]

# setup sqlite
conn = sqlite3.connect(args.dbfile)
conn.row_factory = dict_factory
c = conn.cursor()

spinner = Halo(text=f'Estimating number of entries to be processed ...', spinner='dots')
spinner.start()

# lists all files in FOLDER/catalog/ and prepends their path so operations will resolve
jsonlfiles = [os.path.join(args.folder, 'catalog', x) for x in os.listdir(path=os.path.join(args.folder, 'catalog'))]
jsonlfiles.sort()

sum = 0
for arg in jsonlfiles:
    sum += file_len(arg) # add line length (one row per line)
    sum -= 1 # subtract header
spinner.succeed(text=f'{sum} sections were counted in the provided .jsonl files.')
total_rows = sum

print(f'ðŸ”Ž Inspecting {total_rows} records to enumerate instructors.')

with tqdm(total=total_rows, unit="rows") as t:
    i = 1
    # for every file (each file is a course)
    for arg in jsonlfiles:
        # open file
        with open(arg, 'r') as f:
            j = 0
            # declare variable
            courseName = None
            courseMeta = {}
            for line in f.readlines():
                # load json line as Dict
                obj = json.loads(line)
                if j == 0:
                    # block for creating course document
                    # update progress bar
                    t.set_description(f'[{i}/{len(jsonlfiles)}] {obj["department"]} {obj["catalogNumber"]}')
                    courseName = f'{obj["department"]} {obj["catalogNumber"]}'
                    # save course details for other part of the code
                    courseMeta = copy.deepcopy(obj)
                else:
                    obj["instructors"] = []
                    # for every intructor in the file
                    for item in obj["instructorNames"]:
                        update_instructor(f'{item["lastName"]}, {item["firstName"]}.json', {
                            "firstName": item["firstName"],
                            "lastName": item["lastName"],
                            "GPA": {
                                "minimum": None,
                                "maximum": None,
                                "average": None,
                                "median": None,
                                "range": None,
                                "standardDeviation": None
                            }
                        })
                    t.update()
                j += 1
        i += 1

# lists all files in FOLDER/instructors/
spinner = Halo(text=f'Listing and sorting files in {os.path.join(args.folder, "instructors")}', spinner='dots')
spinner.start()
instructors = os.listdir(path=os.path.join(args.folder, 'instructors'))
instructors.sort()
spinner.succeed()

print(f'ðŸ“Š Computing statistics for {len(instructors)} instructors.')

for item in tqdm(iterable=instructors, total=len(instructors), unit="files"):
    pre = get_instructor(item)
    c.execute('SELECT * FROM records WHERE INSTR_LAST_NAME=? AND INSTR_FIRST_NAME=?', (pre["lastName"], pre["firstName"]))
    sections = c.fetchall()
    # create an array of floats
    grades = [ x["PROF_AVG"] for x in sections ]
    # filter the None values
    grades = list(filter(lambda x: x != None, grades))
    if len(grades) > 0:
        update_instructor(item, {
            "GPA": {
                "minimum": min(grades),
                "maximum": max(grades),
                "average": statistics.mean(grades),
                "median": statistics.median(grades),
                "range": statrange(grades),
                "standardDeviation": statistics.stdev(grades) if len(grades) > 1 else 0
            }
        })



